## Articles

The following articles were used as references for this project:


- [1]X. Zhang, J. Zhao, and Y. LeCun, ‘[Character-level convolutional networks for text classification](https://papers.nips.cc/paper/5782-character-level-convolutional-networks-for-text-classification.pdf)’, in Advances in neural information processing systems, 2015, pp. 649–657.
- [2]T. Miyato, A. M. Dai, and I. Goodfellow, ‘[Adversarial Training Methods for Semi-Supervised Text Classification](https://arxiv.org/pdf/1605.07725.pdf)’, arXiv preprint arXiv:1605.07725, 2016.
- [3]J. Collins, J. Sohl-Dickstein, and D. Sussillo, ‘[Capacity and Trainability in Recurrent Neural Networks](https://arxiv.org/pdf/1611.09913.pdf)’, arXiv preprint arXiv:1611.09913, 2016.
- [4]Y. Kim, ‘[Convolutional neural networks for sentence classification](http://www.aclweb.org/anthology/D14-1181)’, arXiv preprint arXiv:1408.5882, 2014.
- [5]A. Graves, ‘[Generating sequences with recurrent neural networks](https://arxiv.org/pdf/1308.0850.pdf)’, arXiv preprint arXiv:1308.0850, 2013.
- [6]A. Gatt and E. Khramer, ‘[Survey of the State of the Art in Natural Language Generation: Core tasks, applications and evaluation](https://arxiv.org/pdf/1703.09902.pdf)’, Knowledge-Based Systems, vol. 18, no. 4, pp. 235–242, 2017.
- [6]W. Shang, K. Sohn, D. Almeida, and H. Lee, ‘[Understanding and improving convolutional neural networks via concatenated rectified linear units](https://arxiv.org/pdf/1603.05201.pdf)’, in Proceedings of the International Conference on Machine Learning (ICML), 2016.
- [7]M. D. Zeiler and R. Fergus, ‘[Visualizing and understanding convolutional networks](https://arxiv.org/pdf/1311.2901.pdf)’, in European conference on computer vision, 2014, pp. 818–833.
- [8]I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, Y. Bengio, ‘[Generative Adversarial Networks](https://arxiv.org/pdf/1406.2661.pdf)‘, arXiv preprint arXiv:1406.2661v1, 2014

---

## Websites / Blogs

The following websites / blogs were used as references for this project:

- [1]‘Adventures in Narrated Reality – Artists and Machine Intelligence – Medium’. [Online]. Available: [https://medium.com/artists-and-machine-intelligence/adventures-in-narrated-reality-6516ff395ba3](https://medium.com/artists-and-machine-intelligence/adventures-in-narrated-reality-6516ff395ba3). [Accessed: 07-Apr-2017].
- [2]‘NaNoGenMo/2016’, GitHub. [Online]. Available: [https://github.com/NaNoGenMo/2016](https://github.com/NaNoGenMo/2016). [Accessed: 10-Apr-2017].
- [3]A. Karpathy, ‘The Unreasonable Effectiveness of Recurrent Neural Networks’. [Online]. Available: [http://karpathy.github.io/2015/05/21/rnn-effectiveness/](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). [Accessed: 05-Apr-2017].
- [4]François Chollet, ‘How convolutional neural networks see the world’. [Online]. Available: [https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html](https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html). [Accessed: 18-May-2017].

---

## Datasets and pre-trained models

The dataset we've used can be found as [Text files](resources/Text.zip), [Concatened text file]() or [Numpy dumped array]().

The best model we've found so far can be found [here](resources/best_model.hdf5.zip).